import os
import urllib
import time
import html

import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split


def get_query_list(filename):
    directory = str(os.getcwd())
    print(directory)
    filepath = directory + "/" + filename
    data = open(filepath, 'r', encoding='UTF-8').readlines()
    query_list = []
    for d in data:
        # 解码
        d = str(urllib.parse.unquote(d))  # converting url encoded data to simple string
        # print(d)
        query_list.append(d)
    return list(set(query_list))


def get_ngrams(query):
    tempQuery = str(query)
    ngrams = []
    for i in range(0, len(tempQuery) - 3):
        ngrams.append(tempQuery[i:i + 3])
    return ngrams


# 主函数
def getUrlRes(new_queries):
    # # 获取正常请求
    # good_query_list = get_query_list('controller/modeltrain/goodqueries.txt')
    # print(u"正常请求: ", len(good_query_list))
    # for i in range(0, 5):
    #     print(good_query_list[i].strip('\n'))
    # print("\n")
    #
    # # 获取恶意请求
    # bad_query_list = get_query_list('controller/modeltrain/badqueries.txt')
    # print(u"恶意请求: ", len(bad_query_list))
    # for i in range(0, 5):
    #     print(bad_query_list[i].strip('\n'))
    # print("\n")
    #
    # # good_y = [0 for i in range(0, len(good_query_list))]
    # # bad_y = [1 for i in range(0, len(bad_query_list))]
    #
    # queries = bad_query_list + good_query_list
    # # y = bad_y + good_y
    #
    # vectorizer = TfidfVectorizer(tokenizer=get_ngrams)
    #
    # # X = \
    # vectorizer.fit_transform(queries)
    # print(X.shape)
    # # 保存操作
    # joblib.dump(vectorizer, 'modeltrain/vectroizer1.pkl')
    # 加载操作
    vectorizer = joblib.load('controller/modeltrain/vectroizer1.pkl')
    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=42)
    # LR = LogisticRegression()
    # LR.fit(X_train, y_train)
    # print('模型的准确度:{}'.format(LR.score(X_test, y_test)))
    # print("\n")
    # joblib.dump(LR, 'modeltrain/UrlDetection.pkl')
    # 对新的请求列表进行预测
    # new_queries = ['www.foo.com/id=1<script>alert(1)</script>',
    #                'www.foo.com/name=admin\' or 1=1', 'abc.com/admin.php',
    #                '"><svg onload=confirm(1)>',
    #                'test/q=<a href="javascript:confirm(1)>',
    #                'q=../etc/passwd',
    #                '/stylesheet.php?version=1331749579',
    #                '/<script>cross_site_scripting.nasl</script>.idc',
    #                '<img \x39src=x onerror="javascript:alert(1)">',
    #                '/jhot.php?rev=2 |less /etc/passwd']

    urlModel = joblib.load('controller/modeltrain/UrlDetection.pkl')
    X_predict = vectorizer.transform([new_queries])
    res = urlModel.predict(X_predict)
    tmp = "正常请求" if res[0] == 0 else "恶意请求"
    return [new_queries, tmp]

# print(getUrlRes('www.foo.com/id=1<script>alert(1)</script>'))